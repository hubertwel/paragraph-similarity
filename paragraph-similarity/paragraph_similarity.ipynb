{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "paragraph_similarity.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPczmmGdbD49aTVMcTd/PiA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hubertwel/paragraph-similarity/blob/main/paragraph-similarity/paragraph_similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJr_9dXGpJ05",
        "outputId": "07ec6370-1fe8-4387-baca-0f307b2c5453"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "sentences = [\"I ate dinner.\", \n",
        "       \"We had a three-course meal.\", \n",
        "       \"Brad came to dinner with us.\",\n",
        "       \"He loves fish tacos.\",\n",
        "       \"In the end, we all felt like we ate too much.\",\n",
        "       \"We all agreed; it was a magnificent evening.\"]\n",
        "\n",
        "test_sentence = \"I had pizza and pasta.\"\n",
        "\n",
        "# Tokenization of each document\n",
        "sentences_tk = []\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "for s in sentences:\n",
        "    sentence_tk = tokenizer.tokenize(s.lower())\n",
        "    sentences_tk.append(sentence_tk)\n",
        "print('tokenized sentences: ', sentences_tk)\n",
        "print()\n",
        "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(sentences_tk)]\n",
        "print('tagged data: ', tagged_data)\n",
        "print()\n",
        "\n",
        "# Train doc2vec model\n",
        "# vector_size: dimensionality of the feature vectors.\n",
        "# window: the maximum distance between the current and predicted word within a sentence.\n",
        "# min_count: ignores all words with total frequency lower than this.\n",
        "# epochs: preferred number of passes\n",
        "model = Doc2Vec(tagged_data, vector_size = 20, window = 2, min_count = 1, epochs = 100)\n",
        "\n",
        "## Print model vocabulary\n",
        "print('model vocabulary: ', model.wv.vocab)\n",
        "\n",
        "test_sentence_tk = tokenizer.tokenize(test_sentence.lower())\n",
        "print('test_sentence_tk: ', test_sentence_tk)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "tokenized sentences:  [['i', 'ate', 'dinner'], ['we', 'had', 'a', 'three', 'course', 'meal'], ['brad', 'came', 'to', 'dinner', 'with', 'us'], ['he', 'loves', 'fish', 'tacos'], ['in', 'the', 'end', 'we', 'all', 'felt', 'like', 'we', 'ate', 'too', 'much'], ['we', 'all', 'agreed', 'it', 'was', 'a', 'magnificent', 'evening']]\n",
            "\n",
            "tagged data:  [TaggedDocument(words=['i', 'ate', 'dinner'], tags=[0]), TaggedDocument(words=['we', 'had', 'a', 'three', 'course', 'meal'], tags=[1]), TaggedDocument(words=['brad', 'came', 'to', 'dinner', 'with', 'us'], tags=[2]), TaggedDocument(words=['he', 'loves', 'fish', 'tacos'], tags=[3]), TaggedDocument(words=['in', 'the', 'end', 'we', 'all', 'felt', 'like', 'we', 'ate', 'too', 'much'], tags=[4]), TaggedDocument(words=['we', 'all', 'agreed', 'it', 'was', 'a', 'magnificent', 'evening'], tags=[5])]\n",
            "\n",
            "model vocabulary:  {'i': <gensim.models.keyedvectors.Vocab object at 0x7fc444893160>, 'ate': <gensim.models.keyedvectors.Vocab object at 0x7fc4448daf98>, 'dinner': <gensim.models.keyedvectors.Vocab object at 0x7fc447cbf4a8>, 'we': <gensim.models.keyedvectors.Vocab object at 0x7fc447c918d0>, 'had': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9470>, 'a': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb91d0>, 'three': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9128>, 'course': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9208>, 'meal': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9dd8>, 'brad': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9f60>, 'came': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9c88>, 'to': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9978>, 'with': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9f98>, 'us': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9940>, 'he': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9588>, 'loves': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9f28>, 'fish': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9860>, 'tacos': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb96a0>, 'in': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb97b8>, 'the': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9fd0>, 'end': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9e48>, 'all': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9cf8>, 'felt': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9ba8>, 'like': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9b70>, 'too': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9898>, 'much': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9c50>, 'agreed': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9da0>, 'it': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb99b0>, 'was': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9b38>, 'magnificent': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb9eb8>, 'evening': <gensim.models.keyedvectors.Vocab object at 0x7fc447cb99e8>}\n",
            "test_sentence_tk:  ['i', 'had', 'pizza', 'and', 'pasta']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uyNVk1yAbYX",
        "outputId": "f556f1ec-6ad9-485f-e410-0a0a4613debd"
      },
      "source": [
        "pip install --upgrade gensim"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/e0/fa6326251692056dc880a64eb22117e03269906ba55a6864864d24ec8b4e/gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 163kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (4.1.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
            "Installing collected packages: gensim\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-3.8.3\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}